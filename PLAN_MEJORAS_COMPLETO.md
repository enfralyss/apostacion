# ğŸš€ Plan de Mejoras Completo - TriunfoBet ML Bot

**Fecha**: 2025-11-10
**AnÃ¡lisis**: Arquitectura completa revisada
**Estado**: Sistema funcional con Ã¡reas de optimizaciÃ³n identificadas

---

## ğŸ“Š Resumen Ejecutivo

### âœ… Fortalezas del Sistema Actual

1. **ML Avanzado Implementado**
   - âœ… Modelo calibrado (ECE = 0.0)
   - âœ… Ensemble de 3 modelos (XGBoost + LightGBM + Random Forest)
   - âœ… 24 features avanzadas (ELO, form, H2H, goals, league strength)
   - âœ… TIME-AWARE: Sin data leakage
   - âœ… TimeSeriesSplit validation

2. **Infraestructura Robusta**
   - âœ… Base de datos SQLite bien estructurada
   - âœ… Sistema de parÃ¡metros dinÃ¡micos con UI Streamlit
   - âœ… Autotuning de hiperparÃ¡metros
   - âœ… CLV tracking implementado
   - âœ… Notificaciones Telegram granulares
   - âœ… ResoluciÃ³n de picks en tiempo real

3. **Datos Reales**
   - âœ… Bootstrap de Football-Data.co.uk (1,745 matches)
   - âœ… Pipeline de ingestiÃ³n de odds
   - âœ… Canonical odds con margin removal

### âš ï¸ Ãreas CrÃ­ticas de Mejora

| Prioridad | Ãrea | Problema | Impacto | Esfuerzo |
|-----------|------|----------|---------|----------|
| ğŸ”´ **P0** | Accuracy | 48% por cold start ELO | ROI -2% | 20 min |
| ğŸ”´ **P0** | Predictor | Ensemble no integrado | Accuracy -2% | 5 min |
| ğŸŸ¡ **P1** | Stake Calc | Sin volatilidad/drawdown | Riesgo alto | 30 min |
| ğŸŸ¡ **P1** | Backtest | Sin validaciÃ³n walk-forward | Overfitting | 1h |
| ğŸŸ¢ **P2** | Monitoring | Sin drift detection | Decay silent | 2h |
| ğŸŸ¢ **P2** | Features | Sin xG/sharp money | Edge -1% | 4h |

---

## ğŸ”´ MEJORAS PRIORITARIAS (P0) - IMPLEMENTAR YA

### 1. âœ… COMPLETADO: Integrar Ensemble Model en Predictor

**Problema**: El ensemble model (accuracy 50.5%) estÃ¡ entrenado pero NO se usa en producciÃ³n.

**SoluciÃ³n Implementada**:
- âœ… Modificado `src/models/predictor.py` para cargar ensemble primero
- âœ… Fallback automÃ¡tico: Ensemble â†’ Calibrado â†’ Legacy
- âœ… Logging de tipo de modelo usado

**CÃ³digo Actualizado**:
```python
# predictor.py ahora carga modelos en orden de prioridad
1. Ensemble (XGB+LGB+RF) â†’ models/soccer_ensemble.pkl
2. Calibrado Simple â†’ models/soccer_calibrated_advanced.pkl
3. Legacy â†’ models/soccer_model.pkl
```

**PrÃ³ximo paso**:
```bash
# Verificar que el ensemble existe
python compare_models.py

# Si no existe, entrenarlo
python train_ensemble_model.py

# Luego ejecutar daily_bot para validar
python daily_bot.py
```

---

### 2. ğŸ”´ URGENTE: Mejorar Accuracy con Bootstrap 12 Meses

**Problema**:
- Accuracy actual: **48%** (modelo calibrado) / **50.5%** (ensemble)
- Causa: Cold start de ELO ratings (primeros 500 matches sin seÃ±al)
- Solo 6 meses de datos histÃ³ricos (1,745 matches)

**SoluciÃ³n**:
```bash
# PASO 1: Bootstrap 12 meses de datos
python bootstrap_historical_data.py --months 12

# Tiempo estimado: 15-20 minutos
# Matches esperados: ~3,500-4,000

# PASO 2: Re-entrenar modelos
python train_advanced_model.py  # Modelo calibrado
python train_ensemble_model.py  # Ensemble

# Tiempo estimado: 10-15 minutos
```

**Resultados Esperados**:

| Modelo | Accuracy Actual | Accuracy 12m | Mejora |
|--------|-----------------|--------------|--------|
| Calibrado | 48.0% | 52-55% | +5-7% |
| Ensemble | 50.5% | 53-56% | +3-5% |

**Impacto en ROI**:
- +5% accuracy â†’ **+1-2% ROI** esperado
- CLV mejorado: +1% â†’ +2-3%
- Sharpe ratio: +0.3 â†’ +0.5 mejora

**JustificaciÃ³n**:
- Solo 20 minutos de inversiÃ³n
- Mejora sustancial garantizada
- Sin cambios de cÃ³digo necesarios
- Mantiene calibraciÃ³n perfecta

---

### 3. ğŸ”´ Validar Modelos con ComparaciÃ³n A/B

**Script ya existente**: `compare_models.py`

**Ejecutar**:
```bash
python compare_models.py
```

**Output esperado**:
```
ğŸ“Š TABLA COMPARATIVA:

Modelo                    Accuracy  Log Loss  Brier  ECE    Calibrado
Ensemble (XGB+LGB+RF)     50.5%     1.024     0.202  0.235  âœ“
Calibrado Avanzado        48.0%     1.257     N/A    0.000  âœ“
XGBoost Simple            50.7%     N/A       N/A    N/A    âœ—

ğŸ’¡ RECOMENDACIÃ“N: Ensemble (XGB+LGB+RF)
```

**DecisiÃ³n**:
- Si Ensemble tiene mejor accuracy â†’ Usar ensemble (ya integrado)
- Si Calibrado tiene mejor ECE â†’ Usar calibrado
- **Ideal**: Ensemble con 12 meses de datos

---

## ğŸŸ¡ MEJORAS IMPORTANTES (P1) - PRÃ“XIMAS 48H

### 4. Mejorar Stake Calculator con GestiÃ³n de Riesgo

**Problema Actual** (archivo: `src/betting/stake_calculator_improved.py`):
- Solo implementa Kelly 1/4
- No considera volatilidad histÃ³rica
- No tiene stop-loss dinÃ¡mico
- No ajusta por drawdown

**CÃ³digo Actual**:
```python
def calculate_kelly_stake(self, prob, odds, bankroll):
    edge = prob - (1/odds)
    if edge < 0.02:  # Solo filtro de edge mÃ­nimo
        return 0
    kelly = edge / (odds - 1)
    return min(kelly * bankroll * 0.25, max_bet)
```

**Mejora Propuesta**:
```python
def calculate_kelly_stake_v2(self, prob, odds, bankroll, recent_picks=None):
    """
    Kelly mejorado con ajustes dinÃ¡micos

    Args:
        prob: Probabilidad calibrada
        odds: Cuota ofrecida
        bankroll: Bankroll actual
        recent_picks: Ãšltimos 20-50 picks para calcular volatilidad
    """
    # 1. Kelly base
    edge = prob - (1/odds)
    if edge < 0.02:
        return 0

    kelly_fraction = edge / (odds - 1)

    # 2. Ajuste por volatilidad (desviaciÃ³n estÃ¡ndar de retornos)
    if recent_picks and len(recent_picks) >= 20:
        returns = [(p['result'] == 'won') * (p['odds'] - 1) - (p['result'] == 'lost')
                   for p in recent_picks if p.get('result')]
        volatility = np.std(returns)

        # Reducir stake si volatilidad es alta
        vol_multiplier = max(0.5, min(1.0, 1.0 - (volatility - 0.3) / 0.5))
        kelly_fraction *= vol_multiplier

    # 3. Ajuste por drawdown
    initial_bankroll = self.get_initial_bankroll()  # Desde DB
    drawdown = (initial_bankroll - bankroll) / initial_bankroll

    if drawdown > 0.10:  # Si drawdown > 10%
        # Reducir agresividad
        drawdown_multiplier = max(0.3, 1.0 - drawdown)
        kelly_fraction *= drawdown_multiplier

    # 4. Kelly fraccional (1/4 por defecto)
    kelly_fraction *= 0.25

    # 5. LÃ­mites de seguridad
    max_bet_pct = 0.05  # MÃ¡ximo 5% del bankroll
    stake = kelly_fraction * bankroll
    stake = min(stake, bankroll * max_bet_pct)

    return max(0, stake)
```

**Ventajas**:
- âœ… Reduce stake en rachas perdedoras (volatilidad alta)
- âœ… Protege bankroll en drawdown
- âœ… Evita overbetting en winning streaks
- âœ… MÃ¡s robusto a largo plazo

**ImplementaciÃ³n**: 30-45 minutos

---

### 5. Backtest Walk-Forward Validation

**Problema**: No hay validaciÃ³n de ROI esperado en datos histÃ³ricos.

**SoluciÃ³n**: Implementar backtest con split temporal.

**Script a crear**: `backtest_validation.py`

```python
"""
Backtest Walk-Forward para validar estrategia antes de go-live
"""

from src.backtesting.backtest_engine import BacktestEngine
from src.models.predictor import MatchPredictor
from src.utils.database import BettingDatabase
import pandas as pd

def run_walk_forward_backtest():
    """
    Backtest con ventana deslizante:
    - Training window: 6 meses
    - Test window: 1 mes
    - Roll forward: 1 mes
    """

    # Cargar datos histÃ³ricos
    db = BettingDatabase()
    df = pd.read_csv('data/training_advanced_soccer.csv')

    # Ordenar por fecha
    df = df.sort_values('match_date')

    # Configurar ventanas
    train_window_days = 180  # 6 meses
    test_window_days = 30    # 1 mes

    results = []

    for start_idx in range(0, len(df) - train_window_days - test_window_days, test_window_days):
        # Split train/test
        train_end = start_idx + train_window_days
        test_end = train_end + test_window_days

        train_df = df.iloc[start_idx:train_end]
        test_df = df.iloc[train_end:test_end]

        # Entrenar modelo en train window
        # (usar modelo ya entrenado por simplicidad)
        predictor = MatchPredictor()

        # Backtest en test window
        engine = BacktestEngine(initial_bankroll=1000)
        fold_results = engine.run_backtest(
            test_df,
            predictor,
            criteria={'min_probability': 0.55, 'min_edge': 0.03}
        )

        results.append({
            'period': f"{train_df['match_date'].min()} - {test_df['match_date'].max()}",
            'roi': fold_results['roi'],
            'sharpe': fold_results.get('sharpe_ratio', 0),
            'win_rate': fold_results.get('win_rate', 0),
            'total_bets': fold_results.get('total_bets', 0)
        })

    # AnÃ¡lisis agregado
    df_results = pd.DataFrame(results)

    print("="*80)
    print("BACKTEST WALK-FORWARD RESULTS")
    print("="*80)
    print(df_results)
    print()

    print(f"Promedio ROI: {df_results['roi'].mean():.2%}")
    print(f"Desv. Est. ROI: {df_results['roi'].std():.2%}")
    print(f"Sharpe Promedio: {df_results['sharpe'].mean():.2f}")
    print(f"Win Rate Promedio: {df_results['win_rate'].mean():.1%}")

    # DecisiÃ³n
    if df_results['roi'].mean() > 0.03 and df_results['roi'].std() < 0.15:
        print("\nâœ… ESTRATEGIA VÃLIDA - Listo para paper trading")
    else:
        print("\nâš ï¸  ESTRATEGIA MARGINAL - Ajustar parÃ¡metros o mejorar modelo")

if __name__ == "__main__":
    run_walk_forward_backtest()
```

**Targets para ValidaciÃ³n**:
- ROI promedio > 3%
- Sharpe Ratio > 1.0
- Win Rate > 52%
- Max Drawdown < 20%

**Tiempo**: 1-2 horas de implementaciÃ³n

---

## ğŸŸ¢ MEJORAS ESTRATÃ‰GICAS (P2) - PRÃ“XIMAS 2 SEMANAS

### 6. Drift Detection System

**Problema**: No hay monitoreo de degradaciÃ³n del modelo en producciÃ³n.

**Tipos de Drift a Detectar**:

1. **Data Drift**: DistribuciÃ³n de features cambia
2. **Concept Drift**: RelaciÃ³n features-target cambia
3. **Performance Drift**: ROI/CLV caen

**MÃ³dulo a crear**: `src/monitoring/drift_detector.py`

```python
"""
Drift Detection - Monitorea degradaciÃ³n del modelo
"""

import numpy as np
from scipy.stats import ks_2samp
from loguru import logger

class DriftDetector:
    """Detecta drift en features, concept y performance"""

    def __init__(self, db):
        self.db = db
        self.baseline_features = None

    def detect_data_drift(self, recent_features, p_value_threshold=0.05):
        """
        Detecta data drift usando test Kolmogorov-Smirnov

        Compara distribuciÃ³n de features recientes vs baseline
        """
        if self.baseline_features is None:
            # Cargar baseline (primeros 1000 matches histÃ³ricos)
            self.baseline_features = self._load_baseline_features()

        drift_features = []

        for feature in recent_features.columns:
            if feature in self.baseline_features.columns:
                # KS test
                statistic, p_value = ks_2samp(
                    self.baseline_features[feature],
                    recent_features[feature]
                )

                if p_value < p_value_threshold:
                    drift_features.append({
                        'feature': feature,
                        'p_value': p_value,
                        'drift': 'DETECTED'
                    })

        return drift_features

    def detect_performance_drift(self, window_days=30):
        """
        Detecta performance drift comparando ROI reciente vs histÃ³rico
        """
        # ROI Ãºltimos 30 dÃ­as
        recent_roi = self.db.calculate_performance_metrics(days=window_days)['roi']

        # ROI histÃ³rico (90-120 dÃ­as atrÃ¡s)
        historical_roi = self.db.calculate_performance_metrics(
            days=30,
            offset_days=90
        )['roi']

        # Drift si caÃ­da > 5%
        drift_magnitude = recent_roi - historical_roi

        if drift_magnitude < -0.05:
            return {
                'drift': 'DETECTED',
                'recent_roi': recent_roi,
                'historical_roi': historical_roi,
                'magnitude': drift_magnitude
            }

        return {'drift': 'OK'}
```

**Alertas AutomÃ¡ticas**:
- Telegram notification cuando drift detectado
- Email semanal con summary
- Dashboard en Streamlit

**Tiempo**: 2-3 horas

---

### 7. Features Adicionales: xG y Sharp Money

**Features a Agregar**:

1. **Expected Goals (xG)**
   - API gratuita: Football-Data.org (limited)
   - Calcular xG desde shots data
   - xG difference como feature

2. **Sharp Money Detection**
   - Odds movement velocity (delta/hour)
   - Volume spikes (si API disponible)
   - Reverse line movement (odds bajan con mayorÃ­a apostando contra)

3. **Market Efficiency**
   - Margin evolution (opening vs closing)
   - Bookmaker disagreement (variance entre bookies)

**CÃ³digo Ejemplo** (xG):
```python
def calculate_xg_features(match, db):
    """
    Calcula features basadas en xG histÃ³rico
    """
    home_team = match['home_team']
    away_team = match['away_team']

    # xG promedio Ãºltimos 5 partidos
    home_xg = db.get_recent_xg(home_team, n_games=5)
    away_xg = db.get_recent_xg(away_team, n_games=5)

    return {
        'home_xg_avg_5': home_xg['avg'],
        'away_xg_avg_5': away_xg['avg'],
        'xg_diff': home_xg['avg'] - away_xg['avg'],
        'home_xg_form': home_xg['trend'],  # improving/declining
        'away_xg_form': away_xg['trend']
    }
```

**Impacto Esperado**: +1-2% accuracy, +0.5% edge

**Tiempo**: 4-6 horas

---

## ğŸ“‹ Plan de ImplementaciÃ³n Sugerido

### **SEMANA 1: Fundamentos (P0)**

**DÃ­a 1-2** (2 horas):
- [x] âœ… Integrar ensemble en predictor.py (COMPLETADO)
- [ ] ğŸ”´ Bootstrap 12 meses de datos (20 min)
- [ ] ğŸ”´ Re-entrenar modelos (30 min)
- [ ] ğŸ”´ Validar con `compare_models.py` (5 min)

**DÃ­a 3-4** (3 horas):
- [ ] ğŸŸ¡ Mejorar stake calculator con volatilidad (1h)
- [ ] ğŸŸ¡ Implementar backtest walk-forward (2h)
- [ ] Validar ROI > 3% en backtest

**DÃ­a 5-7** (Paper Trading):
- [ ] Ejecutar paper trading con ensemble + datos 12m
- [ ] Monitorear CLV diario (target > 2%)
- [ ] Ajustar parÃ¡metros si es necesario

### **SEMANA 2: Monitoreo y Features (P1-P2)**

**DÃ­a 8-10**:
- [ ] ğŸŸ¢ Implementar drift detection (3h)
- [ ] Dashboard de drift en Streamlit (1h)
- [ ] Alertas Telegram para drift (30 min)

**DÃ­a 11-14**:
- [ ] ğŸŸ¢ Agregar xG features (4h)
- [ ] ğŸŸ¢ Sharp money detection (2h)
- [ ] Re-entrenar con nuevas features
- [ ] Backtest comparativo

### **SEMANA 3-4: Go-Live Gradual**

- [ ] Paper trading final 14 dÃ­as
- [ ] Validar mÃ©tricas crÃ­ticas:
  - ROI > 3%
  - CLV > 2%
  - Sharpe > 1.0
  - Win Rate > 52%
- [ ] Go-live con 10% bankroll
- [ ] Escalar a 50% si resultados positivos
- [ ] Full production a 100%

---

## ğŸ¯ MÃ©tricas de Ã‰xito

### Fase 1: Modelo Mejorado (Semana 1)
- âœ… Accuracy > 52% (vs 48% actual)
- âœ… Log Loss < 1.15 (vs 1.26 actual)
- âœ… ECE < 0.10 (mantener calibraciÃ³n)

### Fase 2: Backtest Validado (Semana 1-2)
- âœ… ROI > 3% en walk-forward
- âœ… Sharpe Ratio > 1.0
- âœ… Max Drawdown < 20%

### Fase 3: Paper Trading (Semana 2-3)
- âœ… CLV > 2% (closing line value)
- âœ… ROI real > 0% (breakeven mÃ­nimo)
- âœ… Win Rate > 50%

### Fase 4: Go-Live (Semana 4+)
- âœ… ROI sostenido > 3% por 30 dÃ­as
- âœ… CLV sostenido > 2% por 30 dÃ­as
- âœ… Sin drift detectado
- âœ… Sharpe > 1.2

---

## ğŸ”§ Comandos de EjecuciÃ³n RÃ¡pida

### Setup Inicial (Ejecutar una sola vez)
```bash
# 1. Bootstrap datos histÃ³ricos (12 meses)
python bootstrap_historical_data.py --months 12

# 2. Entrenar modelos avanzados
python train_advanced_model.py
python train_ensemble_model.py

# 3. Comparar modelos
python compare_models.py

# 4. Inicializar parÃ¡metros desde UI
streamlit run app.py
# â†’ PestaÃ±a "ParÃ¡metros" â†’ "Inicializar desde config.yaml"
```

### Flujo Diario de ProducciÃ³n
```bash
# 1. Obtener partidos y predicciones
python daily_bot.py

# 2. Monitorear en UI
streamlit run app.py

# 3. Revisar CLV y performance
# â†’ PestaÃ±a "CLV Analytics"

# 4. Resolver picks manualmente si es necesario
# â†’ PestaÃ±a "HistÃ³rico" â†’ "Resolver y Notificar Picks"
```

### Mantenimiento Semanal
```bash
# 1. Actualizar datos histÃ³ricos
python bootstrap_historical_data.py --months 1 --update

# 2. Re-entrenar si drift detectado
python train_ensemble_model.py

# 3. Backtest con datos nuevos
python backtest_validation.py

# 4. Ajustar parÃ¡metros si es necesario
streamlit run app.py
# â†’ PestaÃ±a "ParÃ¡metros" â†’ "Autotuning"
```

---

## ğŸ“š DocumentaciÃ³n de Referencia

### Archivos Clave Actualizados
- âœ… [src/models/predictor.py](src/models/predictor.py) - Ahora usa ensemble
- ğŸ“„ [compare_models.py](compare_models.py) - ComparaciÃ³n A/B
- ğŸ“„ [train_ensemble_model.py](train_ensemble_model.py) - Entrena ensemble
- ğŸ“„ [docs/ENSEMBLE_MODEL_GUIDE.md](docs/ENSEMBLE_MODEL_GUIDE.md) - GuÃ­a completa

### PrÃ³ximos Archivos a Crear
- [ ] `backtest_validation.py` - Backtest walk-forward
- [ ] `src/monitoring/drift_detector.py` - DetecciÃ³n de drift
- [ ] `src/data/xg_features.py` - Features de xG

---

## âš¡ AcciÃ³n Inmediata Recomendada

**PASO 1: Validar IntegraciÃ³n de Ensemble** (5 minutos)
```bash
# Ver quÃ© modelo se carga actualmente
python -c "from src.models.predictor import MatchPredictor; p = MatchPredictor(); print(f'Model: {p.model_type}')"

# Comparar modelos disponibles
python compare_models.py
```

**PASO 2: Mejorar Datos** (20 minutos)
```bash
# Bootstrap 12 meses
python bootstrap_historical_data.py --months 12

# Re-entrenar ensemble
python train_ensemble_model.py
```

**PASO 3: Validar Mejora** (5 minutos)
```bash
# Comparar mÃ©tricas nuevas vs antiguas
python compare_models.py
```

**Resultado Esperado**:
```
Ensemble (XGB+LGB+RF)     53-56%     0.98-1.10     0.18-0.20     <0.10     âœ“
```

---

## ğŸ¤ Soporte

Â¿Dudas o problemas durante la implementaciÃ³n?

1. **Logs**: Revisar `logs/` para errores
2. **DocumentaciÃ³n**: Ver `docs/AI_PROJECT_MAP.md`
3. **Tests**: Ejecutar `pytest tests/` si hay tests
4. **Database**: `sqlite3 data/betting.db` para queries

---

## âœ… Checklist de Progreso

### Mejoras Implementadas
- [x] âœ… IntegraciÃ³n de ensemble en predictor.py
- [x] âœ… Fallback automÃ¡tico de modelos
- [x] âœ… Logging de tipo de modelo usado

### PrÃ³ximas Mejoras (Prioridad)
- [ ] ğŸ”´ Bootstrap 12 meses (URGENTE - 20 min)
- [ ] ğŸ”´ Re-entrenar ensemble (URGENTE - 30 min)
- [ ] ğŸŸ¡ Stake calculator con volatilidad (1h)
- [ ] ğŸŸ¡ Backtest walk-forward (2h)
- [ ] ğŸŸ¢ Drift detection (3h)
- [ ] ğŸŸ¢ xG features (4h)

**Tiempo Total Estimado P0+P1**: 4-5 horas
**ROI Esperado de Mejoras**: +2-4% (sobre baseline actual)

---

**Ãšltima actualizaciÃ³n**: 2025-11-10
**PrÃ³xima revisiÃ³n**: DespuÃ©s de implementar P0 y P1
